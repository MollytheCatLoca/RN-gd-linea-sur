#!/bin/bash
# Script para crear todos los archivos Python del proyecto EDERSA
# Ejecutar DESPU√âS de cleanup_for_edersa_complete.sh

echo "üêç Creando archivos Python para EDERSA..."

# 1. CREAR transformer_loader.py
cat > src/inventory/transformer_loader.py << 'EOF'
"""
Cargador de inventario de transformadores EDERSA
"""
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class Transformer:
    """Modelo de datos para transformador"""
    codigo: str
    sucursal: str
    alimentador: str
    potencia_kva: float
    usuarios: int
    localidad: str
    coord_x: Optional[float] = None
    coord_y: Optional[float] = None
    resultado: Optional[str] = None
    penalized: bool = False
    
    @property
    def has_coordinates(self) -> bool:
        return self.coord_x is not None and self.coord_y is not None
    
    @property
    def quality_score(self) -> float:
        """Score de calidad: 1.0 = Correcta, 0.5 = Penalizada, 0.0 = Fallida"""
        if self.resultado == 'Correcta':
            return 1.0
        elif self.resultado == 'Penalizada':
            return 0.5
        elif self.resultado == 'Fallida':
            return 0.0
        return np.nan


class TransformerInventoryLoader:
    """Carga y procesa el inventario de transformadores EDERSA"""
    
    def __init__(self, data_path: Path):
        self.data_path = data_path
        self.raw_data = None
        self.transformers = []
        
    def load_excel(self, file_name: str = "Mediciones Originales EDERSA.xlsx") -> pd.DataFrame:
        """Carga el archivo Excel de EDERSA"""
        file_path = self.data_path / file_name
        logger.info(f"Cargando inventario desde {file_path}")
        
        try:
            self.raw_data = pd.read_excel(file_path, sheet_name='Hoja 1')
            logger.info(f"Cargados {len(self.raw_data)} registros")
            return self.raw_data
        except Exception as e:
            logger.error(f"Error cargando archivo: {e}")
            raise
            
    def process_inventory(self) -> List[Transformer]:
        """Procesa el inventario y crea objetos Transformer"""
        if self.raw_data is None:
            raise ValueError("Debe cargar los datos primero con load_excel()")
            
        transformers = []
        
        for idx, row in self.raw_data.iterrows():
            try:
                transformer = Transformer(
                    codigo=str(row['Codigoct']),
                    sucursal=str(row['N_Sucursal']) if pd.notna(row['N_Sucursal']) else 'SIN_SUCURSAL',
                    alimentador=str(row['Alimentador']) if pd.notna(row['Alimentador']) else 'SIN_ALIMENTADOR',
                    potencia_kva=float(row['Potencia']) if pd.notna(row['Potencia']) else 0.0,
                    usuarios=int(row['Q_Usuarios']) if pd.notna(row['Q_Usuarios']) else 0,
                    localidad=str(row['N_Localida']) if pd.notna(row['N_Localida']) else 'SIN_LOCALIDAD',
                    coord_x=float(row['Coord_X']) if pd.notna(row['Coord_X']) else None,
                    coord_y=float(row['Coord_Y']) if pd.notna(row['Coord_Y']) else None,
                    resultado=str(row['Resultado']) if pd.notna(row['Resultado']) else None,
                    penalized=row['Resultado'] in ['Penalizada', 'Fallida'] if pd.notna(row['Resultado']) else False
                )
                transformers.append(transformer)
            except Exception as e:
                logger.warning(f"Error procesando registro {idx}: {e}")
                continue
                
        self.transformers = transformers
        logger.info(f"Procesados {len(transformers)} transformadores")
        return transformers
        
    def get_summary(self) -> Dict:
        """Genera resumen del inventario"""
        if not self.transformers:
            raise ValueError("Debe procesar el inventario primero")
            
        df = pd.DataFrame([t.__dict__ for t in self.transformers])
        
        summary = {
            'total_transformers': len(self.transformers),
            'total_capacity_mva': df['potencia_kva'].sum() / 1000,
            'total_users': df['usuarios'].sum(),
            'transformers_with_quality': df['resultado'].notna().sum(),
            'penalized_transformers': df['penalized'].sum(),
            'transformers_with_coordinates': sum(t.has_coordinates for t in self.transformers),
            'by_branch': df.groupby('sucursal').size().to_dict(),
            'by_feeder': df.groupby('alimentador').size().to_dict(),
            'quality_distribution': df['resultado'].value_counts().to_dict()
        }
        
        return summary
EOF

# 2. CREAR quality_analyzer.py
cat > src/quality/quality_analyzer.py << 'EOF'
"""
Analizador de calidad de servicio EDERSA
"""
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class QualityAnalyzer:
    """Analiza calidad de servicio por transformador"""
    
    def __init__(self, transformers: List):
        self.transformers = transformers
        self.df = pd.DataFrame([t.__dict__ for t in transformers])
        
    def analyze_by_zone(self, zone_column: str = 'sucursal') -> pd.DataFrame:
        """Analiza calidad por zona (sucursal, alimentador, etc.)"""
        
        quality_by_zone = self.df.groupby(zone_column).agg({
            'codigo': 'count',
            'potencia_kva': 'sum',
            'usuarios': 'sum',
            'penalized': ['sum', 'mean'],
            'quality_score': 'mean'
        })
        
        quality_by_zone.columns = [
            'total_transformers', 
            'total_kva', 
            'total_users',
            'penalized_count',
            'penalized_rate',
            'avg_quality_score'
        ]
        
        # Calcular criticidad
        quality_by_zone['criticality_index'] = (
            quality_by_zone['penalized_rate'] * 0.4 +
            (1 - quality_by_zone['avg_quality_score']) * 0.3 +
            (quality_by_zone['penalized_count'] / quality_by_zone['total_transformers']) * 0.3
        )
        
        return quality_by_zone.sort_values('criticality_index', ascending=False)
        
    def identify_critical_zones(self, top_n: int = 10) -> List[Dict]:
        """Identifica las zonas m√°s cr√≠ticas"""
        
        # Por sucursal
        by_branch = self.analyze_by_zone('sucursal')
        
        # Por alimentador
        by_feeder = self.analyze_by_zone('alimentador')
        
        critical_zones = []
        
        # Top sucursales cr√≠ticas
        for branch in by_branch.head(top_n).index:
            zone_data = by_branch.loc[branch]
            critical_zones.append({
                'type': 'branch',
                'name': branch,
                'criticality_index': zone_data['criticality_index'],
                'penalized_transformers': int(zone_data['penalized_count']),
                'affected_users': int(zone_data['total_users']),
                'total_capacity_mva': zone_data['total_kva'] / 1000
            })
            
        return critical_zones
        
    def calculate_impact_metrics(self) -> Dict:
        """Calcula m√©tricas de impacto del problema de calidad"""
        
        total_users = self.df['usuarios'].sum()
        affected_users = self.df[self.df['penalized']]['usuarios'].sum()
        
        total_capacity = self.df['potencia_kva'].sum()
        affected_capacity = self.df[self.df['penalized']]['potencia_kva'].sum()
        
        metrics = {
            'total_users': int(total_users),
            'affected_users': int(affected_users),
            'users_impact_rate': affected_users / total_users if total_users > 0 else 0,
            'total_capacity_mva': total_capacity / 1000,
            'affected_capacity_mva': affected_capacity / 1000,
            'capacity_impact_rate': affected_capacity / total_capacity if total_capacity > 0 else 0,
            'avg_transformer_size_kva': total_capacity / len(self.df) if len(self.df) > 0 else 0,
            'transformers_by_quality': self.df['resultado'].value_counts().to_dict()
        }
        
        return metrics
EOF

# 3. CREAR geographic_clustering.py
cat > src/clustering/geographic_clustering.py << 'EOF'
"""
Clustering geogr√°fico para identificar zonas √≥ptimas de GD
"""
import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN, KMeans
from typing import List, Dict, Tuple
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class GeographicClusterer:
    """Agrupa transformadores geogr√°ficamente para identificar ubicaciones √≥ptimas de GD"""
    
    def __init__(self, transformers: List):
        self.transformers = transformers
        # Filtrar solo transformadores con coordenadas
        self.geo_transformers = [t for t in transformers if t.has_coordinates]
        logger.info(f"Transformadores con coordenadas: {len(self.geo_transformers)}")
        
    def cluster_by_density(self, eps: float = 0.01, min_samples: int = 5) -> Dict[int, List]:
        """Clustering por densidad usando DBSCAN"""
        
        # Preparar coordenadas
        coords = np.array([[t.coord_x, t.coord_y] for t in self.geo_transformers])
        
        # Aplicar DBSCAN
        clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)
        
        # Agrupar transformadores por cluster
        clusters = defaultdict(list)
        for idx, label in enumerate(clustering.labels_):
            clusters[label].append(self.geo_transformers[idx])
            
        logger.info(f"Clusters encontrados: {len(clusters) - 1} (excluyendo ruido)")
        return dict(clusters)
        
    def find_optimal_gd_locations(self, n_locations: int = 10) -> List[Dict]:
        """Encuentra ubicaciones √≥ptimas para GD basado en criticidad y densidad"""
        
        # Filtrar transformadores problem√°ticos con coordenadas
        critical_transformers = [
            t for t in self.geo_transformers 
            if t.penalized
        ]
        
        if len(critical_transformers) < n_locations:
            logger.warning(f"Solo {len(critical_transformers)} transformadores cr√≠ticos con coordenadas")
            n_locations = len(critical_transformers)
            
        # Preparar datos para clustering
        coords = np.array([[t.coord_x, t.coord_y] for t in critical_transformers])
        weights = np.array([t.usuarios * t.potencia_kva for t in critical_transformers])
        
        # K-means ponderado
        kmeans = KMeans(n_clusters=n_locations, random_state=42)
        kmeans.fit(coords, sample_weight=weights)
        
        # Analizar cada cluster
        locations = []
        for i in range(n_locations):
            cluster_mask = kmeans.labels_ == i
            cluster_transformers = [t for t, m in zip(critical_transformers, cluster_mask) if m]
            
            if not cluster_transformers:
                continue
                
            # Centro del cluster
            center = kmeans.cluster_centers_[i]
            
            # Calcular m√©tricas del cluster
            total_users = sum(t.usuarios for t in cluster_transformers)
            total_kva = sum(t.potencia_kva for t in cluster_transformers)
            
            locations.append({
                'location_id': i,
                'latitude': center[1],
                'longitude': center[0],
                'transformers_count': len(cluster_transformers),
                'affected_users': total_users,
                'total_capacity_kva': total_kva,
                'priority_score': total_users * 0.6 + total_kva * 0.4,
                'nearest_branch': self._find_nearest_branch(center[0], center[1])
            })
            
        # Ordenar por prioridad
        locations.sort(key=lambda x: x['priority_score'], reverse=True)
        return locations
        
    def _find_nearest_branch(self, lon: float, lat: float) -> str:
        """Encuentra la sucursal m√°s cercana a una coordenada"""
        min_dist = float('inf')
        nearest = None
        
        for t in self.geo_transformers:
            if t.sucursal != 'SIN_SUCURSAL':
                dist = np.sqrt((t.coord_x - lon)**2 + (t.coord_y - lat)**2)
                if dist < min_dist:
                    min_dist = dist
                    nearest = t.sucursal
                    
        return nearest or 'DESCONOCIDA'
EOF

# 4. CREAR requirements_edersa.txt
cat > requirements_edersa.txt << 'EOF'
# Core
pandas>=2.0.0
numpy>=1.24.0
openpyxl>=3.1.0
xlrd>=2.0.0

# Visualizaci√≥n
plotly>=5.14.0
dash>=2.10.0
dash-bootstrap-components>=1.4.0
folium>=0.14.0
matplotlib>=3.7.0
seaborn>=0.12.0

# An√°lisis
scipy>=1.10.0
scikit-learn>=1.2.0
statsmodels>=0.14.0

# Utilidades
python-dotenv>=1.0.0
pydantic>=2.0.0
click>=8.1.0

# Testing
pytest>=7.3.0
pytest-cov>=4.1.0

# Desarrollo
black>=23.0.0
flake8>=6.0.0
jupyter>=1.0.0
EOF

# 5. CREAR app_edersa.py
cat > dashboard/app_edersa.py << 'EOF'
"""
Dashboard principal para an√°lisis EDERSA
"""
import dash
from dash import dcc, html, Input, Output, State
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from pathlib import Path
import sys

# Agregar src al path
sys.path.append(str(Path(__file__).parent.parent))

from src.inventory.transformer_loader import TransformerInventoryLoader
from src.quality.quality_analyzer import QualityAnalyzer
from src.clustering.geographic_clustering import GeographicClusterer

# Inicializar app
app = dash.Dash(__name__, suppress_callback_exceptions=True)

# Cargar datos
data_path = Path(__file__).parent.parent / "data" / "raw"
loader = TransformerInventoryLoader(data_path)
loader.load_excel()
transformers = loader.process_inventory()

# Analizar calidad
analyzer = QualityAnalyzer(transformers)
quality_by_branch = analyzer.analyze_by_zone('sucursal')
impact_metrics = analyzer.calculate_impact_metrics()

# Layout principal
app.layout = html.Div([
    html.H1("EDERSA - An√°lisis de Calidad y Oportunidades GD", 
            style={'textAlign': 'center', 'marginBottom': 30}),
    
    # Tabs
    dcc.Tabs([
        dcc.Tab(label='Resumen General', children=[
            html.Div([
                # KPIs
                html.Div([
                    html.Div([
                        html.H3(f"{impact_metrics['total_users']:,}"),
                        html.P("Usuarios Totales")
                    ], className='kpi-box'),
                    
                    html.Div([
                        html.H3(f"{impact_metrics['affected_users']:,}"),
                        html.P("Usuarios Afectados"),
                        html.P(f"({impact_metrics['users_impact_rate']:.1%})", 
                               style={'color': 'red'})
                    ], className='kpi-box'),
                    
                    html.Div([
                        html.H3(f"{impact_metrics['total_capacity_mva']:.1f} MVA"),
                        html.P("Capacidad Total")
                    ], className='kpi-box'),
                    
                    html.Div([
                        html.H3(f"{impact_metrics['affected_capacity_mva']:.1f} MVA"),
                        html.P("Capacidad Afectada"),
                        html.P(f"({impact_metrics['capacity_impact_rate']:.1%})", 
                               style={'color': 'orange'})
                    ], className='kpi-box'),
                ], style={'display': 'flex', 'justifyContent': 'space-around'}),
                
                # Gr√°ficos
                html.Div([
                    dcc.Graph(
                        id='quality-by-branch',
                        figure=px.bar(
                            quality_by_branch.reset_index(),
                            x='sucursal',
                            y='penalized_rate',
                            title='Tasa de Penalizaci√≥n por Sucursal',
                            labels={'penalized_rate': 'Tasa de Penalizaci√≥n', 
                                   'sucursal': 'Sucursal'}
                        )
                    )
                ], style={'marginTop': 30})
            ])
        ]),
        
        dcc.Tab(label='Mapa de Transformadores', children=[
            html.Div([
                html.H3("Distribuci√≥n Geogr√°fica de Transformadores"),
                html.Div(id='map-container'),
                html.Button('Generar Mapa', id='generate-map-btn', 
                           style={'marginTop': 20})
            ])
        ]),
        
        dcc.Tab(label='Zonas Cr√≠ticas', children=[
            html.Div([
                html.H3("Identificaci√≥n de Zonas Cr√≠ticas"),
                html.Div(id='critical-zones-table'),
                dcc.Graph(id='criticality-scatter')
            ])
        ]),
        
        dcc.Tab(label='Ubicaciones GD', children=[
            html.Div([
                html.H3("Ubicaciones √ìptimas para Generaci√≥n Distribuida"),
                html.P("N√∫mero de ubicaciones a identificar:"),
                dcc.Slider(
                    id='n-locations-slider',
                    min=5,
                    max=20,
                    step=1,
                    value=10,
                    marks={i: str(i) for i in range(5, 21, 5)}
                ),
                html.Button('Calcular Ubicaciones', id='calculate-locations-btn',
                           style={'marginTop': 20}),
                html.Div(id='gd-locations-results', style={'marginTop': 30})
            ])
        ])
    ])
], style={'padding': 20})


# Callbacks
@app.callback(
    Output('critical-zones-table', 'children'),
    Output('criticality-scatter', 'figure'),
    Input('critical-zones-table', 'id')  # Dummy input
)
def update_critical_zones(_):
    """Actualiza an√°lisis de zonas cr√≠ticas"""
    critical = analyzer.identify_critical_zones(top_n=15)
    
    # Tabla
    table_data = []
    for zone in critical:
        table_data.append({
            'Zona': zone['name'],
            'Tipo': zone['type'],
            '√çndice Criticidad': f"{zone['criticality_index']:.3f}",
            'Transformadores Penalizados': zone['penalized_transformers'],
            'Usuarios Afectados': f"{zone['affected_users']:,}",
            'Capacidad (MVA)': f"{zone['total_capacity_mva']:.1f}"
        })
    
    df_table = pd.DataFrame(table_data)
    
    # Gr√°fico scatter
    fig = px.scatter(
        df_table,
        x='Usuarios Afectados',
        y='Transformadores Penalizados',
        size='Capacidad (MVA)',
        color='√çndice Criticidad',
        hover_data=['Zona'],
        title='An√°lisis de Criticidad por Zona'
    )
    
    table = html.Table([
        html.Thead([
            html.Tr([html.Th(col) for col in df_table.columns])
        ]),
        html.Tbody([
            html.Tr([html.Td(df_table.iloc[i][col]) for col in df_table.columns])
            for i in range(len(df_table))
        ])
    ])
    
    return table, fig


@app.callback(
    Output('gd-locations-results', 'children'),
    Input('calculate-locations-btn', 'n_clicks'),
    State('n-locations-slider', 'value')
)
def calculate_gd_locations(n_clicks, n_locations):
    """Calcula ubicaciones √≥ptimas para GD"""
    if not n_clicks:
        return html.Div()
    
    # Clustering geogr√°fico
    clusterer = GeographicClusterer(transformers)
    locations = clusterer.find_optimal_gd_locations(n_locations)
    
    # Crear visualizaci√≥n
    results = []
    for i, loc in enumerate(locations[:10]):  # Top 10
        results.append(
            html.Div([
                html.H4(f"Ubicaci√≥n {i+1}: {loc['nearest_branch']}"),
                html.P(f"Coordenadas: ({loc['latitude']:.4f}, {loc['longitude']:.4f})"),
                html.P(f"Transformadores afectados: {loc['transformers_count']}"),
                html.P(f"Usuarios beneficiados: {loc['affected_users']:,}"),
                html.P(f"Capacidad total: {loc['total_capacity_kva']:,.0f} kVA"),
                html.Hr()
            ])
        )
    
    return html.Div(results)


# Estilos CSS
app.index_string = '''
<!DOCTYPE html>
<html>
    <head>
        {%metas%}
        <title>{%title%}</title>
        {%favicon%}
        {%css%}
        <style>
            .kpi-box {
                border: 1px solid #ddd;
                padding: 20px;
                margin: 10px;
                text-align: center;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .kpi-box h3 {
                margin: 0;
                color: #2c3e50;
            }
            .kpi-box p {
                margin: 5px 0;
            }
            table {
                width: 100%;
                border-collapse: collapse;
                margin-top: 20px;
            }
            th, td {
                border: 1px solid #ddd;
                padding: 8px;
                text-align: left;
            }
            th {
                background-color: #f2f2f2;
            }
        </style>
    </head>
    <body>
        {%app_entry%}
        <footer>
            {%config%}
            {%scripts%}
            {%renderer%}
        </footer>
    </body>
</html>
'''


if __name__ == '__main__':
    app.run_server(debug=True)
EOF

# 6. CREAR README_EDERSA.md
cat > README.md << 'EOF'
# GD-EDERSA-CALIDAD
## An√°lisis de Calidad de Servicio y Oportunidades de Generaci√≥n Distribuida

### üéØ Objetivo
Identificar ubicaciones √≥ptimas para instalaci√≥n de Generaci√≥n Distribuida (GD) en la red EDERSA, bas√°ndose en el an√°lisis de calidad de servicio de 14,025 transformadores.

### üìä Datos Disponibles
- **Inventario completo** de transformadores EDERSA
- **Resultados de calidad** (Correcta/Penalizada/Fallida)
- **Ubicaci√≥n geogr√°fica** de cada transformador
- **Capacidad instalada** y usuarios por transformador

### üöÄ Inicio R√°pido

```bash
# Activar entorno
source venv/bin/activate

# Instalar dependencias
pip install -r requirements_edersa.txt

# Ejecutar dashboard
cd dashboard
python app_edersa.py
```

### üìÅ Estructura del Proyecto

```
gd-edersa-calidad/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ inventory/        # Manejo de inventario de transformadores
‚îÇ   ‚îú‚îÄ‚îÄ quality/          # An√°lisis de calidad de servicio
‚îÇ   ‚îú‚îÄ‚îÄ clustering/       # Agrupaci√≥n geogr√°fica y por criticidad
‚îÇ   ‚îî‚îÄ‚îÄ optimization/     # Optimizaci√≥n de ubicaciones GD
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/             # Excel original EDERSA
‚îÇ   ‚îî‚îÄ‚îÄ processed/       # Datos procesados
‚îú‚îÄ‚îÄ dashboard/           # Visualizaci√≥n interactiva
‚îú‚îÄ‚îÄ docs/               # Documentaci√≥n
‚îî‚îÄ‚îÄ tests/              # Tests unitarios
```

### üîç Metodolog√≠a

1. **An√°lisis de Inventario**: Procesamiento del Excel con 14,025 transformadores
2. **Evaluaci√≥n de Calidad**: Identificaci√≥n de 2,731 transformadores problem√°ticos
3. **Clustering Geogr√°fico**: Agrupaci√≥n por densidad y criticidad
4. **Priorizaci√≥n**: Ranking de zonas por impacto en usuarios
5. **Dimensionamiento GD**: Estimaci√≥n preliminar sin series temporales

### üìà Resultados Preliminares

- **34% de transformadores** con problemas de calidad
- **~180,000 usuarios afectados** (estimado)
- **Top 3 sucursales cr√≠ticas**: [Se completar√° con an√°lisis]
- **10 ubicaciones √≥ptimas** para GD identificadas

### üõ†Ô∏è Pr√≥ximos Pasos

1. Solicitar **series temporales** de demanda
2. Obtener **topolog√≠a de red** detallada
3. Integrar **costos de penalizaciones**
4. Realizar **simulaciones** de impacto GD

### üë• Equipo
- An√°lisis t√©cnico: [Tu nombre]
- Framework base: Proyecto L√≠nea Sur RN

### üìù Licencia
Proyecto para EDERSA - Ente Distribuidor de Electricidad de R√≠o Negro S.A.
EOF

echo "‚úÖ Archivos Python creados exitosamente!"
echo ""
echo "üìã Estado del proyecto:"
echo "- M√≥dulos Python: ‚úì"
echo "- Requirements: ‚úì"
echo "- Dashboard: ‚úì"
echo "- README: ‚úì"
echo ""
echo "üöÄ Para comenzar:"
echo "1. python -m venv venv"
echo "2. source venv/bin/activate"
echo "3. pip install -r requirements_edersa.txt"
echo "4. cd dashboard && python app_edersa.py"